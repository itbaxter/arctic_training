---
title: "cleaning_practice1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Reformat Catch Data

- Remove the "all" column (Just pretend it's a sum)
- create a species column & table 
    - move from wide to long
- General QA

# Join the Region Definitions


# Misc. Functions

```{r, warning = FALSE, message = FALSE}
library(dplyr)
library(tidyr)

# to call stats filter - stats::filter()
```
R will use the function with the same name from different packages from the package that was loaded most recently.

Reading Data from a data archive.

[Mike Byerly. Alaska commercial salmon catches by management region (1886- 1997). Gulf of Alaska Data Portal. df35b.304.2.](https://knb.ecoinformatics.org/view/df35b.304.2)

```{r}
catch_original <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1", method ="libcurl"), stringsAsFactors = FALSE)
regdefs <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.303.1", method = "libcurl"), stringsAsFactors = FALSE)
head(catch_original)
```

1. Remove the `all` and `notesRegCode` columns using `seclect`
    - Pipe Operator (%>%)

Cmd + shift : pipe operator shortcut %>%

2. Move from wide to long format

```{r}
catch_long <- catch_original %>%
    select(-All, -notesRegCode) %>% # Add a -[variable_name] to remove
    gather(key = "species", value = "catch", -Region, -Year) # creates key-value pairs and then gathers with other specified columns

head(catch_long)
```

```{r}
catch_wide <- catch_long %>%
    spread(key = species, value = catch)

head(catch_wide)
```
```{r}
catch_Wide <- catch_long %>%
    spread(key = "Region", value = "catch")

head(catch_Wide)
```

# Clean up our data

* rename catch to catch_thousands
* create a new catch column in units num. of fish `#`
* create a new catch column in units num. of fish

```{r}
catch_clean <- catch_long %>%
    rename(catch_thousands = catch) %>%
    mutate(catch_thousands = ifelse(catch_thousands == "I", 1, catch_thousands)) %>%
    mutate(catch_thousands = as.numeric(catch_thousands)) %>%
    mutate(catch = catch_thousands * 1000) %>%
    select(-catch_thousands)

head(catch_clean)
```

Check to see where the value is messing everything up.
```{r, echo = FALSE, eval = FALSE}
# look for where as.numeric failed
test <- as.numeric(catch_long$catch)
i <- which(is.na(test) == TRUE)
catch_long[i,] 
```

## Split - Apply - Combine

* calculate the mean catch by species

```{r}
year_mean <- catch_clean %>%
    group_by(Year) %>%
    summarize(catch_mean = mean(catch),
              num_obs = n()) %>%
    arrange(-Year) %>%
    filter(Year >= 1989 | Year <= 1960) # &=and, |=or

head(year_mean)
```

Do not usually use grou_by and mutate together
```{r}
year_mean <- catch_clean %>%
    group_by(Year) %>%
    mutate(catch_mean = mean(catch),
              num_obs = n()) %>%
    arrange(-Year) %>%
    filter(Year >= 1989 | Year <= 1960) # &=and, |=or

head(year_mean)
```

```{r}
region_defs <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.303.1",
                            method = "libcurl"),
                        stringsAsFactors = FALSE) %>% 
    select(code, mgmtArea) # %>%
    # rename(Region)

head(region_defs)
```

If you do an inner join it would get rid of rows with N/A
If you do an outer join it will have some rows with N/A
```{r}
catch_joined <- left_join(catch_clean, region_defs, by = c("Region" = "code"))

head(catch_joined)
```

```{r}
dates_df <- data.frame(date = c("5/24/1930",
                                "5/25/1930",
                                "5/26/1930",
                                "5/27/1930",
                                "5/28/1930"),
                       stringsAsFactors = FALSE)

```

Split seperates strings/characters at the first non-alpha numeric value.
There is a package(stringr) for first three letters/numbers.
```{r}
dates_split <- dates_df %>%
    # separate(date, into = c("month", "day", "year"), sep = "/")
    separate(date, into = c("month", "day", "year"), sep = "/", remove = F)
  
head(dates_split)
```

opposite of split() = unite()
```{r}
dates_unite <- dates_split %>%
    unite(col = date_iso, year, month, day, sep = "-")

head(dates_unite)
```

```{r}
library(stringr)

str_pad("5", 2, side = "left", pad = "0")
```

Always put row.names=F otherwise it'll give you two columns of row names.
```{r}
write.csv(catch_clean, "catch_clean.csv", row.names = F)
```
